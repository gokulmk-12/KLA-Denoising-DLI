{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wF2GWdiUm-Nb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 10:43:19.268718: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/gokul/.mujoco/mujoco210/bin:/opt/ros/noetic/lib:/opt/ros/noetic/lib/x86_64-linux-gnu:/usr/lib/nvidia\n",
      "2024-11-02 10:43:19.268755: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QcQniKqam-Nc"
   },
   "outputs": [],
   "source": [
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, transform=None, patch_size=None, is_train=True):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.image_names = os.listdir(image_dir)\n",
    "        self.patch_size = patch_size\n",
    "        self.is_train = is_train\n",
    "        self.num_patches_per_image = (256 // patch_size)**2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)*self.num_patches_per_image\n",
    "\n",
    "    def extract_patches(self, image, patch_size):\n",
    "        _, h, w = image.size()\n",
    "        patches = []\n",
    "\n",
    "        for i in range(0, h, patch_size):\n",
    "            for j in range(0, w, patch_size):\n",
    "                patch = image[:, i:i + patch_size, j:j + patch_size]\n",
    "                if patch.size(1) == patch_size and patch.size(2) == patch_size:\n",
    "                    patches.append(patch)\n",
    "\n",
    "        return patches\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_idx = idx // self.num_patches_per_image\n",
    "        patch_idx = idx % self.num_patches_per_image\n",
    "\n",
    "        img_name = self.image_names[img_idx]\n",
    "\n",
    "        image = Image.open(os.path.join(\n",
    "            self.image_dir, img_name)).convert('RGB')\n",
    "        label = Image.open(os.path.join(\n",
    "            self.label_dir, img_name)).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            label = self.transform(label)\n",
    "\n",
    "        if self.is_train:\n",
    "            image_patches = self.extract_patches(image, self.patch_size)\n",
    "            label_patches = self.extract_patches(label, self.patch_size)\n",
    "            return image_patches[patch_idx], label_patches[patch_idx]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "E8wpjf2Qm-Nd"
   },
   "outputs": [],
   "source": [
    "image_size = 256\n",
    "\n",
    "Transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_image_dir = '../Project/dataset/data/Train'\n",
    "train_label_dir = '../Project/dataset/label/Train'\n",
    "val_image_dir = '../Project/dataset/data/Val'\n",
    "val_label_dir = '../Project/dataset/label/Val'\n",
    "\n",
    "trainDataset = DenoisingDataset(\n",
    "    train_image_dir, train_label_dir, Transform, patch_size=64, is_train=True)\n",
    "valDataset = DenoisingDataset(\n",
    "    val_image_dir, val_label_dir, Transform, patch_size=256, is_train=False)\n",
    "\n",
    "batchSize = 16\n",
    "trainLoader = DataLoader(trainDataset, batch_size=batchSize, shuffle=True)\n",
    "valLoader = DataLoader(valDataset, batch_size=batchSize, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932\n"
     ]
    }
   ],
   "source": [
    "print(len(trainLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NLwGAGcxm-Nd"
   },
   "outputs": [],
   "source": [
    "class EAM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EAM, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=3, dilation=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=3, dilation=2, padding=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=3, dilation=3, padding=3)\n",
    "        self.conv4 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=3, dilation=4, padding=4)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(\n",
    "            in_channels=128, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv11 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.norm = nn.LayerNorm([64, 256, 256])\n",
    "\n",
    "        for layer in [self.conv1, self.conv2, self.conv3, self.conv4, self.conv5, self.conv6,\n",
    "                      self.conv7, self.conv8, self.conv9, self.conv10, self.conv11, self.conv12]:\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x1 = F.silu(self.conv1(image))\n",
    "        x1 = F.silu(self.conv2(x1))\n",
    "\n",
    "        x2 = F.silu(self.conv3(image))\n",
    "        x2 = F.silu(self.conv4(x2))\n",
    "\n",
    "        x1_x2 = torch.cat([x1, x2], dim=1)\n",
    "        x3 = F.silu(self.conv5(x1_x2))\n",
    "        add1 = image + x3\n",
    "\n",
    "        x4 = F.silu(self.conv6(add1))\n",
    "        x4 = self.conv7(x4)\n",
    "        add2 = x4 + add1\n",
    "        add2 = F.silu(add2)\n",
    "\n",
    "        x5 = F.silu(self.conv8(add2))\n",
    "        x5 = F.silu(self.conv9(x5))\n",
    "        x5 = self.conv10(x5)\n",
    "\n",
    "        add3 = add2 + x5\n",
    "        add3 = F.silu(add3)\n",
    "\n",
    "        gap = F.adaptive_avg_pool2d(add3, (1, 1))\n",
    "        x6 = F.silu(self.conv11(gap))\n",
    "        x6 = torch.sigmoid(self.conv12(x6))\n",
    "\n",
    "        mul = x6 * add3\n",
    "        output = image + mul\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class RIDNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RIDNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.eam = nn.Sequential(\n",
    "            EAM(),\n",
    "            EAM(),\n",
    "            EAM(),\n",
    "            EAM()\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=64, out_channels=3, kernel_size=3, padding=1)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.conv1.weight)\n",
    "        nn.init.xavier_uniform_(self.conv2.weight)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.conv1(image)\n",
    "        x = self.eam(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        output = image + x\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rKMqCMH3m-Ne"
   },
   "outputs": [],
   "source": [
    "os.makedirs('saved_models', exist_ok=True)\n",
    "writer = SummaryWriter(log_dir='logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oP050Cyzm-Ne",
    "outputId": "abcab8b0-6108-4a4e-d6ee-9799a901bd3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "model = RIDNet()\n",
    "# model = model.to(device)\n",
    "\n",
    "X, y = next(iter(valLoader))\n",
    "output = model(X[:8,:,:,:])\n",
    "# output = model(X.to(device))\n",
    "print(output.shape)\n",
    "\n",
    "# summary(model, (3, 256, 256), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-UOeSnGm-Ne",
    "outputId": "f32f2ac4-75c2-45f6-ad24-33ab7cd959b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4238/2983626323.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded Successfully !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/40: 100%|██████████| 932/932 [15:59<00:00,  1.03s/batch, loss=0.00085] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40, Training Loss:  0.00097\n",
      "Model weights saved at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/40: 100%|██████████| 932/932 [16:00<00:00,  1.03s/batch, loss=0.000629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/40, Training Loss:  0.00097\n",
      "Model weights saved at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/40: 100%|██████████| 932/932 [15:57<00:00,  1.03s/batch, loss=0.00112] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40, Training Loss:  0.00097\n",
      "Model weights saved at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/40: 100%|██████████| 932/932 [15:58<00:00,  1.03s/batch, loss=0.00126] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/40, Training Loss:  0.00097\n",
      "Model weights saved at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/40: 100%|██████████| 932/932 [15:54<00:00,  1.02s/batch, loss=0.000924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/40, Training Loss:  0.00097\n",
      "Model weights saved at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/40: 100%|██████████| 932/932 [15:56<00:00,  1.03s/batch, loss=0.000641]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40, Training Loss:  0.00097\n",
      "Model weights saved at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/40: 100%|██████████| 932/932 [15:54<00:00,  1.02s/batch, loss=0.000662]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40, Training Loss:  0.00097\n",
      "Model weights saved at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/40: 100%|██████████| 932/932 [15:52<00:00,  1.02s/batch, loss=0.000831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/40, Training Loss:  0.00097\n",
      "Model weights saved at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/40: 100%|██████████| 932/932 [15:51<00:00,  1.02s/batch, loss=0.000658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/40, Training Loss:  0.00097\n",
      "Model weights saved at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/40: 100%|██████████| 932/932 [15:53<00:00,  1.02s/batch, loss=0.00118] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40, Training Loss:  0.00097\n",
      "Model weights saved at epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/40: 100%|██████████| 932/932 [15:53<00:00,  1.02s/batch, loss=0.00125] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40, Training Loss:  0.00097\n",
      "Model weights saved at epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/40: 100%|██████████| 932/932 [15:52<00:00,  1.02s/batch, loss=0.000963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/40, Training Loss:  0.00096\n",
      "Model weights saved at epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/40: 100%|██████████| 932/932 [15:54<00:00,  1.02s/batch, loss=0.00131] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40, Training Loss:  0.00096\n",
      "Model weights saved at epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/40: 100%|██████████| 932/932 [15:49<00:00,  1.02s/batch, loss=0.00152] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40, Training Loss:  0.00096\n",
      "Model weights saved at epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/40: 100%|██████████| 932/932 [15:51<00:00,  1.02s/batch, loss=0.00117] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40, Training Loss:  0.00096\n",
      "Model weights saved at epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/40: 100%|██████████| 932/932 [15:49<00:00,  1.02s/batch, loss=0.00133] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/40, Training Loss:  0.00096\n",
      "Model weights saved at epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/40: 100%|██████████| 932/932 [15:50<00:00,  1.02s/batch, loss=0.000686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40, Training Loss:  0.00096\n",
      "Model weights saved at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/40: 100%|██████████| 932/932 [15:50<00:00,  1.02s/batch, loss=0.000795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/40, Training Loss:  0.00096\n",
      "Model weights saved at epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/40: 100%|██████████| 932/932 [15:50<00:00,  1.02s/batch, loss=0.00126] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/40, Training Loss:  0.00096\n",
      "Model weights saved at epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/40: 100%|██████████| 932/932 [15:51<00:00,  1.02s/batch, loss=0.000722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40, Training Loss:  0.00096\n",
      "Model weights saved at epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/40: 100%|██████████| 932/932 [15:52<00:00,  1.02s/batch, loss=0.000796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/40, Training Loss:  0.00096\n",
      "Model weights saved at epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/40: 100%|██████████| 932/932 [15:51<00:00,  1.02s/batch, loss=0.00104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/40, Training Loss:  0.00095\n",
      "Model weights saved at epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/40: 100%|██████████| 932/932 [15:47<00:00,  1.02s/batch, loss=0.00106] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/40, Training Loss:  0.00095\n",
      "Model weights saved at epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/40: 100%|██████████| 932/932 [15:49<00:00,  1.02s/batch, loss=0.000581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/40, Training Loss:  0.00095\n",
      "Model weights saved at epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/40: 100%|██████████| 932/932 [15:48<00:00,  1.02s/batch, loss=0.00161] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/40, Training Loss:  0.00095\n",
      "Model weights saved at epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/40: 100%|██████████| 932/932 [15:47<00:00,  1.02s/batch, loss=0.000914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40, Training Loss:  0.00095\n",
      "Model weights saved at epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/40: 100%|██████████| 932/932 [15:46<00:00,  1.02s/batch, loss=0.00104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/40, Training Loss:  0.00095\n",
      "Model weights saved at epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/40: 100%|██████████| 932/932 [15:49<00:00,  1.02s/batch, loss=0.00161] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/40, Training Loss:  0.00095\n",
      "Model weights saved at epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/40: 100%|██████████| 932/932 [15:46<00:00,  1.02s/batch, loss=0.000685]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/40, Training Loss:  0.00095\n",
      "Model weights saved at epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/40: 100%|██████████| 932/932 [15:51<00:00,  1.02s/batch, loss=0.00117] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/40, Training Loss:  0.00095\n",
      "Model weights saved at epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/40: 100%|██████████| 932/932 [15:47<00:00,  1.02s/batch, loss=0.000989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/40, Training Loss:  0.00095\n",
      "Model weights saved at epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/40: 100%|██████████| 932/932 [15:52<00:00,  1.02s/batch, loss=0.000972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/40, Training Loss:  0.00095\n",
      "Model weights saved at epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/40: 100%|██████████| 932/932 [15:49<00:00,  1.02s/batch, loss=0.000702]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/40, Training Loss:  0.00095\n",
      "Model weights saved at epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/40: 100%|██████████| 932/932 [15:52<00:00,  1.02s/batch, loss=0.00104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/40, Training Loss:  0.00094\n",
      "Model weights saved at epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/40: 100%|██████████| 932/932 [16:03<00:00,  1.03s/batch, loss=0.00108] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/40, Training Loss:  0.00094\n",
      "Model weights saved at epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/40: 100%|██████████| 932/932 [15:58<00:00,  1.03s/batch, loss=0.00147] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/40, Training Loss:  0.00094\n",
      "Model weights saved at epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/40: 100%|██████████| 932/932 [15:56<00:00,  1.03s/batch, loss=0.000994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/40, Training Loss:  0.00094\n",
      "Model weights saved at epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/40: 100%|██████████| 932/932 [15:55<00:00,  1.03s/batch, loss=0.00112] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/40, Training Loss:  0.00094\n",
      "Model weights saved at epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/40: 100%|██████████| 932/932 [16:10<00:00,  1.04s/batch, loss=0.00144] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/40, Training Loss:  0.00094\n",
      "Model weights saved at epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/40: 100%|██████████| 932/932 [15:55<00:00,  1.03s/batch, loss=0.000914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/40, Training Loss:  0.00094\n",
      "Model weights saved at epoch 40\n",
      "Model Weights Saved Successfully\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Define loss function, optimizer, and scheduler\n",
    "model_path = \"/home/keerthi/KLA project/ridnet3_epoch_16patch29oct.pth\"\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print(\"Model Loaded Successfully !\")\n",
    "model.to(device)\n",
    "lossfn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "# Training parameters\n",
    "epochs = 40\n",
    "trainLosses, valLosses = [], []\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    runningLoss = 0.0\n",
    "\n",
    "    # Use tqdm for batch loop progress\n",
    "    with tqdm(enumerate(trainLoader), total=len(trainLoader), desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\") as pbar:\n",
    "        for batchIdx, (images, labels) in pbar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            yHat = model(images)\n",
    "            l1_loss = lossfn(yHat, labels)\n",
    "            total_loss = l1_loss\n",
    "\n",
    "            # Backpropagation and optimization step\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log progress\n",
    "            writer.add_scalar('Loss/Train', total_loss.item(),\n",
    "                              epoch*len(trainLoader)+batchIdx)\n",
    "            runningLoss += total_loss.item()\n",
    "\n",
    "            # Update tqdm progress bar with current loss\n",
    "            pbar.set_postfix({'loss': total_loss.item()})\n",
    "\n",
    "    # Scheduler step at the end of the epoch\n",
    "    scheduler.step()\n",
    "\n",
    "    # Calculate average training loss for the epoch\n",
    "    avg_train_loss = runningLoss / len(trainLoader)\n",
    "    trainLosses.append(avg_train_loss)\n",
    "    writer.add_scalar('Training Loss', avg_train_loss, epoch)\n",
    "\n",
    "    # Print and log the loss for the epoch\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Training Loss: {avg_train_loss: .5f}')\n",
    "\n",
    "    # Save model weights every 5 epochs\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        torch.save(model.state_dict(), f\"ridnet3_epoch_16patch29oct.pth\")\n",
    "        print(f\"Model weights saved at epoch {epoch+1}\")\n",
    "\n",
    "# Final save of the model weights after training\n",
    "torch.save(model.state_dict(), \"ridnet3_model.pth\")\n",
    "print(\"Model Weights Saved Successfully\")\n",
    "\n",
    "# Close the writer to ensure everything is written to disk\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19552/4224812140.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded Successfully !\n"
     ]
    }
   ],
   "source": [
    "model_path = \"../Project/saved_models/ridnet3_epoch_16patch29oct.pth\"\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print(\"Model Loaded Successfully !\")\n",
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 29.5089\n",
      "Average SSIM: 0.8579\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchmetrics import PeakSignalNoiseRatio\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "\n",
    "# Initialize PSNR metric\n",
    "model = model.to('cpu')\n",
    "psnr_metric = PeakSignalNoiseRatio().to('cpu')\n",
    "\n",
    "# Accumulators for PSNR and SSIM values\n",
    "total_psnr = 0\n",
    "total_ssim = 0\n",
    "num_batches = 0\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    for Xval, yVal in valLoader:\n",
    "        # Ensure data is on the CPU\n",
    "        Xval, yVal = Xval.cpu(), yVal.cpu()\n",
    "\n",
    "        # Get model prediction\n",
    "        yval_pred = model(Xval).cpu()  # Keep everything on CPU\n",
    "\n",
    "        # Calculate PSNR for the batch\n",
    "        total_psnr += psnr_metric(yval_pred, yVal).item()\n",
    "\n",
    "        # Calculate SSIM for each image in the batch, using win_size=3 for small images\n",
    "        batch_ssim_values = []\n",
    "        for i in range(yVal.size(0)):\n",
    "            # Ensure conversion to NumPy\n",
    "            pred_img = np.array(yval_pred[i].squeeze().cpu())\n",
    "            true_img = np.array(yVal[i].squeeze().cpu())\n",
    "            # Calculate SSIM, ensuring compatibility with data_range and win_size\n",
    "            ssim_value = ssim(\n",
    "                true_img, pred_img, data_range=true_img.max() - true_img.min(), win_size=3)\n",
    "            batch_ssim_values.append(ssim_value)\n",
    "\n",
    "        # Average SSIM for the batch and accumulate\n",
    "        batch_ssim = np.mean(batch_ssim_values)\n",
    "        total_ssim += batch_ssim\n",
    "        num_batches += 1\n",
    "\n",
    "# Calculate average PSNR and SSIM across all batches\n",
    "average_psnr = total_psnr / num_batches\n",
    "average_ssim = total_ssim / num_batches\n",
    "\n",
    "print(f\"Average PSNR: {average_psnr:.4f}\")\n",
    "print(f\"Average SSIM: {average_ssim:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "valLoader = DataLoader(valDataset, batch_size=batchSize, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get a batch from the validation loader and move to CPU\n",
    "Xval, yVal = next(iter(valLoader))\n",
    "Xval = Xval.to('cpu')\n",
    "yVal = yVal.to('cpu')\n",
    "model = model.to('cpu')\n",
    "\n",
    "# Run the model on the entire batch\n",
    "yvalPred = model(Xval)\n",
    "\n",
    "# Set up a figure with 3 columns to display the images side-by-side\n",
    "_, ax = plt.subplots(ncols=3, nrows=1, figsize=(15, 5))\n",
    "\n",
    "# Select the specific sample within the batch (0 to 15)\n",
    "select_sample = 0  # Adjust this to select a different sample within the batch range\n",
    "\n",
    "# Display Noisy Image (input)\n",
    "ax[0].imshow(Xval[select_sample].detach().numpy().transpose(1, 2, 0))\n",
    "ax[0].set_title(\"Noisy Image\")\n",
    "\n",
    "# Display Clean Image (target)\n",
    "ax[1].imshow(yVal[select_sample].detach().numpy().transpose(1, 2, 0))\n",
    "ax[1].set_title(\"Clean Image\")\n",
    "\n",
    "# Display Restored Image (model output)\n",
    "ax[2].imshow(yvalPred[select_sample].detach().numpy().transpose(1, 2, 0))\n",
    "ax[2].set_title(\"Restored Image\")\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.512714862823486,\n",
       " 8.647907257080078,\n",
       " 8.253816604614258,\n",
       " 8.396913528442383,\n",
       " 8.402873039245605,\n",
       " 8.349210739135742,\n",
       " 7.125802040100098,\n",
       " 8.017643928527832]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def PSNR(ground_truth, predicted_image):\n",
    "    mse = F.mse_loss(predicted_image, ground_truth)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    max_pixel = 1.0\n",
    "    psnr = 20 * torch.log10(torch.tensor(max_pixel)/torch.sqrt(mse))\n",
    "    return psnr.item()\n",
    "\n",
    "\n",
    "psnrVals = []\n",
    "for i in range(0, 8):\n",
    "    psnr = PSNR(output[i, :, :, :], y[i, :, :, :])\n",
    "    psnrVals.append(psnr)\n",
    "psnrVals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76714975"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_ssim(img1, img2):\n",
    "    img1 = img1.cpu().detach().numpy()\n",
    "    img2 = img2.cpu().detach().numpy()\n",
    "\n",
    "    if img1.ndim == 3 and img1.shape[0] == 3:\n",
    "        img1 = np.moveaxis(img1, 0, -1)\n",
    "        img2 = np.moveaxis(img2, 0, -1)\n",
    "\n",
    "    score, _ = ssim(img1, img2, full=True, channel_axis=2,\n",
    "                    data_range=img1.max() - img1.min())\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "calculate_ssim(yvalPred[1, :, :, :], yVal[33, :, :, :])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
